# interesting-papers

* [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/pdf/2305.10601)
* [ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models](https://arxiv.org/pdf/2305.14323)
* [CHAIN-OF-VERIFICATION REDUCES HALLUCINATION IN LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2309.11495)
* [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](https://arxiv.org/abs/2305.04091)
  * [Lemon Agent is a standalone supervised Plan and Solve Agent](https://github.com/felixbrock/lemon-agent)
* [Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment](https://arxiv.org/pdf/2401.12474)
* [LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models](https://arxiv.org/pdf/2310.05736)
* [Improving Factuality and Reasoning in Language Models through Multiagent Debate](https://arxiv.org/abs/2305.14325)
  * [Project](https://composable-models.github.io/llm_debate/)
  * [Github repo](https://github.com/composable-models/llm_multiagent_debate?tab=readme-ov-file)
* [Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation](https://arxiv.org/pdf/2305.16938)
* [Better Zero-Shot Reasoning with Self-Adaptive Prompting](https://arxiv.org/pdf/2305.14106)
* [FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/pdf/2105.03824)
* [TransformerFAM: Feedback attention is working memory](https://arxiv.org/pdf/2404.09173)
* [HiPPO: Recurrent Memory with Optimal Polynomial Projections](https://arxiv.org/pdf/2008.07669)
* [Reducing Activation Recomputation in Large Transformer Models](https://arxiv.org/pdf/2205.05198)
* [Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://arxiv.org/pdf/2401.09417)
* [More Agents Is All You Need](https://arxiv.org/pdf/2402.05120)
* [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/pdf/2312.00752)

# medium posts, other sites

* [A Complete Guide to LLMs-based Autonomous Agents (Part I)](https://medium.com/the-modern-scientist/a-complete-guide-to-llms-based-autonomous-agents-part-i-69515c016792)
* [Chain-of-Thought Prompting](https://www.promptingguide.ai/techniques/cot)

# also about some interesting repos, site links

* [The original BabyAGI from March 2023 introduced task planning as a method for developing autonomous agents](https://github.com/yoheinakajima/babyagi)
* [BabyBeeAGI: Task Management and Functionality Expansion on top of BabyAGI](https://yoheinakajima.com/babybeeagi-task-management-and-functionality-expansion-on-top-of-babyagi/)
* [Letta (previously MemGPT) is an open source framework for building stateful LLM applications. You can use Letta to build stateful agents with advanced reasoning capabilities and transparent long-term memory](https://github.com/cpacker/MemGPT)
* [MiniAGI is a simple autonomous agent compatible with GPT-3.5-Turbo and GPT-4. It combines a robust prompt with a minimal set of tools, chain-of-thoughts, and short-term memory with summarization. It is also capable of inner monologue and self-criticism](https://github.com/muellerberndt/mini-agi)
* [Teenage-AGI, Inspired by several Auto-GPT-related Projects (predominantly BabyAGI)](https://github.com/seanpixel/Teenage-AGI/blob/main/README.md#experiments)
* [WorkGPT is an agent framework in a similar fashion to AutoGPT or LangChain](https://github.com/team-openpm/workgpt)
* [Awesome Agents is a curated list of open source AI agents](https://github.com/kyrolabs/awesome-agents)
* [A collection of autonomous agents ü§ñÔ∏è powered by LLM](https://github.com/Jenqyang/Awesome-AI-Agents)
* [We introduce a novel LLM-based multimodal agent framework designed to operate smartphone applications](https://github.com/mnotgod96/AppAgent)
